{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fb44f6d",
   "metadata": {},
   "source": [
    "# SageMaker JumpStart - deploy automatic speech recognition model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2bc55e",
   "metadata": {
    "tags": []
   },
   "source": [
    "This notebook demonstrates how to use the SageMaker Python SDK to deploy a JumpStart automatic speech recognition model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b54b344-16db-4334-804d-7b2c8d631eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import time\n",
    "import boto3\n",
    "import json\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket() # Set a default S3 bucket\n",
    "prefix = 'whisper-sm-js'\n",
    "role = sagemaker.get_execution_role()\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "\n",
    "# below boto3 clients are for invoking asynchronous endpoint \n",
    "sm = boto3.client(\"sagemaker\")\n",
    "sm_runtime = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "# S3 client\n",
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a357fa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import boto3\n",
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "from sagemaker.jumpstart.utils import get_jumpstart_content_bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89965762",
   "metadata": {},
   "source": [
    "Select your desired model ID. You can search for available models in the [Built-in Algorithms with pre-trained Model Table](https://sagemaker.readthedocs.io/en/stable/doc_utils/pretrainedmodels.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb9d688c",
   "metadata": {
    "jumpStartAlterations": [
     "modelIdOnly"
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"huggingface-asr-whisper-small\"\n",
    "\n",
    "#\"huggingface-asr-whisper-large-v3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867badfa",
   "metadata": {},
   "source": [
    "## Deploy model\n",
    "\n",
    "Using the model ID, define your model as a JumpStart model. You can deploy the model on other instance types by passing `instance_type` to `JumpStartModel`. See [Deploy publicly available foundation models with the JumpStartModel class](https://docs.aws.amazon.com/sagemaker/latest/dg/jumpstart-foundation-models-use-python-sdk.html#jumpstart-foundation-models-use-python-sdk-model-class) for more configuration options.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4cf4668c-3dd5-4cc6-93c8-029701fc8b8a",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using model 'huggingface-asr-whisper-small' with wildcard version identifier '*'. You can pin to version '3.0.0' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n"
     ]
    }
   ],
   "source": [
    "model = JumpStartModel(model_id=model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a30060c-7602-4c5f-a2b9-e9430a78fa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "container = model.image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a7ff371-c812-4a12-94ec-0e3e509d2a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://jumpstart-cache-prod-us-west-2/huggingface-asr/huggingface-asr-whisper-small/artifacts/inference-prepack/v2.0.0/'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_artifacts = model.model_data[\"S3DataSource\"][\"S3Uri\"]\n",
    "code_artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c3c343-b873-49be-a79f-2af20c9edf3e",
   "metadata": {},
   "source": [
    "You can now deploy your JumpStart model. The deployment might take few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8db9ab85-a97c-499f-ab43-c111d8e16879",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://jumpstart-cache-prod-us-west-2/huggingface-asr/huggingface-asr-whisper-small/artifacts/inference-prepack/v2.0.0/added_tokens.json to code/added_tokens.json\n",
      "download: s3://jumpstart-cache-prod-us-west-2/huggingface-asr/huggingface-asr-whisper-small/artifacts/inference-prepack/v2.0.0/__model_info__.json to code/__model_info__.json\n",
      "download: s3://jumpstart-cache-prod-us-west-2/huggingface-asr/huggingface-asr-whisper-small/artifacts/inference-prepack/v2.0.0/code/__init__.py to code/code/__init__.py\n",
      "download: s3://jumpstart-cache-prod-us-west-2/huggingface-asr/huggingface-asr-whisper-small/artifacts/inference-prepack/v2.0.0/code/__script_info__.json to code/code/__script_info__.json\n",
      "download: s3://jumpstart-cache-prod-us-west-2/huggingface-asr/huggingface-asr-whisper-small/artifacts/inference-prepack/v2.0.0/code/constants/__pycache__/constants.cpython-310.pyc to code/code/constants/__pycache__/constants.cpython-310.pyc\n",
      "download: s3://jumpstart-cache-prod-us-west-2/huggingface-asr/huggingface-asr-whisper-small/artifacts/inference-prepack/v2.0.0/code/constants/constants.py to code/code/constants/constants.py\n",
      "download: s3://jumpstart-cache-prod-us-west-2/huggingface-asr/huggingface-asr-whisper-small/artifacts/inference-prepack/v2.0.0/code/script_requirements.txt to code/code/script_requirements.txt\n",
      "download: s3://jumpstart-cache-prod-us-west-2/huggingface-asr/huggingface-asr-whisper-small/artifacts/inference-prepack/v2.0.0/code/requirements.txt to code/code/requirements.txt\n",
      "download: s3://jumpstart-cache-prod-us-west-2/huggingface-asr/huggingface-asr-whisper-small/artifacts/inference-prepack/v2.0.0/code/constants/__pycache__/__init__.cpython-310.pyc to code/code/constants/__pycache__/__init__.cpython-310.pyc\n",
      "download: s3://jumpstart-cache-prod-us-west-2/huggingface-asr/huggingface-asr-whisper-small/artifacts/inference-prepack/v2.0.0/code/__pycache__/__init__.cpython-310.pyc to code/code/__pycache__/__init__.cpython-310.pyc\n",
      "download: s3://jumpstart-cache-prod-us-west-2/huggingface-asr/huggingface-asr-whisper-small/artifacts/inference-prepack/v2.0.0/code/version to code/code/version\n",
      "download: s3://jumpstart-cache-prod-us-west-2/huggingface-asr/huggingface-asr-whisper-small/artifacts/inference-prepack/v2.0.0/code/constants/__init__.py to code/code/constants/__init__.py\n",
      "download: s3://jumpstart-cache-prod-us-west-2/huggingface-asr/huggingface-asr-whisper-small/artifacts/inference-prepack/v2.0.0/preprocessor_config.json to code/preprocessor_config.json\n",
      "download: s3://jumpstart-cache-prod-us-west-2/huggingface-asr/huggingface-asr-whisper-small/artifacts/inference-prepack/v2.0.0/generation_config.json to code/generation_config.json\n",
      "download: s3://jumpstart-cache-prod-us-west-2/huggingface-asr/huggingface-asr-whisper-small/artifacts/inference-prepack/v2.0.0/config.json to code/config.json\n",
      "download: s3://jumpstart-cache-prod-us-west-2/huggingface-asr/huggingface-asr-whisper-small/artifacts/inference-prepack/v2.0.0/code/audio_validation.py to code/code/audio_validation.py\n",
      "download: s3://jumpstart-cache-prod-us-west-2/huggingface-asr/huggingface-asr-whisper-small/artifacts/inference-prepack/v2.0.0/normalizer.json to code/normalizer.json\n",
      "download: s3://jumpstart-cache-prod-us-west-2/huggingface-asr/huggingface-asr-whisper-small/artifacts/inference-prepack/v2.0.0/code/inference.py to code/code/inference.py\n",
      "download: s3://jumpstart-cache-prod-us-west-2/huggingface-asr/huggingface-asr-whisper-small/artifacts/inference-prepack/v2.0.0/special_tokens_map.json to code/special_tokens_map.json\n",
      "download: s3://jumpstart-cache-prod-us-west-2/huggingface-asr/huggingface-asr-whisper-small/artifacts/inference-prepack/v2.0.0/merges.txt to code/merges.txt\n",
      "download: s3://jumpstart-cache-prod-us-west-2/huggingface-asr/huggingface-asr-whisper-small/artifacts/inference-prepack/v2.0.0/code/lib/transformers/transformers-4.39.3-py3-none-any.whl to code/code/lib/transformers/transformers-4.39.3-py3-none-any.whl\n",
      "download: s3://jumpstart-cache-prod-us-west-2/huggingface-asr/huggingface-asr-whisper-small/artifacts/inference-prepack/v2.0.0/vocab.json to code/vocab.json\n",
      "download: s3://jumpstart-cache-prod-us-west-2/huggingface-asr/huggingface-asr-whisper-small/artifacts/inference-prepack/v2.0.0/tokenizer_config.json to code/tokenizer_config.json\n",
      "download: s3://jumpstart-cache-prod-us-west-2/huggingface-asr/huggingface-asr-whisper-small/artifacts/inference-prepack/v2.0.0/tokenizer.json to code/tokenizer.json\n",
      "download: s3://jumpstart-cache-prod-us-west-2/huggingface-asr/huggingface-asr-whisper-small/artifacts/inference-prepack/v2.0.0/model.safetensors to code/model.safetensors\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p code\n",
    "\n",
    "!aws s3 sync {code_artifacts} code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e5581cc-026b-4462-8464-a79b0ceae1b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: code/__model_info__.json to s3://sagemaker-us-west-2-376678947624/whisper-sm-js/uncompressed/model/__model_info__.json\n",
      "upload: code/config.json to s3://sagemaker-us-west-2-376678947624/whisper-sm-js/uncompressed/model/config.json\n",
      "upload: code/preprocessor_config.json to s3://sagemaker-us-west-2-376678947624/whisper-sm-js/uncompressed/model/preprocessor_config.json\n",
      "upload: code/added_tokens.json to s3://sagemaker-us-west-2-376678947624/whisper-sm-js/uncompressed/model/added_tokens.json\n",
      "upload: code/generation_config.json to s3://sagemaker-us-west-2-376678947624/whisper-sm-js/uncompressed/model/generation_config.json\n",
      "upload: code/special_tokens_map.json to s3://sagemaker-us-west-2-376678947624/whisper-sm-js/uncompressed/model/special_tokens_map.json\n",
      "upload: code/tokenizer_config.json to s3://sagemaker-us-west-2-376678947624/whisper-sm-js/uncompressed/model/tokenizer_config.json\n",
      "upload: code/vocab.json to s3://sagemaker-us-west-2-376678947624/whisper-sm-js/uncompressed/model/vocab.json\n",
      "upload: code/tokenizer.json to s3://sagemaker-us-west-2-376678947624/whisper-sm-js/uncompressed/model/tokenizer.json\n",
      "upload: code/model.safetensors to s3://sagemaker-us-west-2-376678947624/whisper-sm-js/uncompressed/model/model.safetensors\n"
     ]
    }
   ],
   "source": [
    "uncompressed_path = f\"s3://{bucket}/{prefix}/uncompressed/model/\"\n",
    "!aws s3 sync code {uncompressed_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5b31fba5-d1bf-490d-8aab-a71986640da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data={\n",
    "    'S3DataSource': {\n",
    "        'S3Uri': uncompressed_path,\n",
    "        'S3DataType': 'S3Prefix',\n",
    "        'CompressionType': 'None'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8f443aa2-6054-428c-84c9-7b03996f259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "\n",
    "model_name = name_from_base(f\"{prefix}-model\")\n",
    "\n",
    "model = Model(\n",
    "    image_uri=container,\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    env={\n",
    "        \"ENDPOINT_SERVER_TIMEOUT\":\"3600\",\n",
    "        \"MODEL_CACHE_ROOT\": \"/opt/ml/model\",\n",
    "        'SAGEMAKER_ENV': '1',\n",
    "        'SAGEMAKER_PROGRAM': 'inference.py'\n",
    "    },\n",
    "    name=model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "acdf77fc-1407-4a13-b12f-ccc8aa22d73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------!"
     ]
    }
   ],
   "source": [
    "endpoint_name = name_from_base(f\"{prefix}-endpoint\")\n",
    "# deploy model to SageMaker Inference\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g5.2xlarge\",\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded32929",
   "metadata": {},
   "source": [
    "## Invoke endpoint\n",
    "\n",
    "The following cell creates a helper function to download an audio file for the automatic speech recognition. You will pass this file to the predictor for inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "847c8cc7-df30-41dd-965f-bbcae61efab8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def download_and_load_audio_file(file_name):\n",
    "    s3_bucket = get_jumpstart_content_bucket()\n",
    "    s3_prefix = \"training-datasets/asr_notebook_data\"\n",
    "    s3_client = boto3.client(\"s3\")\n",
    "    s3_client.download_file(s3_bucket, f\"{s3_prefix}/{file_name}\", file_name)\n",
    "    with open(file_name, \"rb\") as file:\n",
    "        input_audio = file.read()\n",
    "    return input_audio\n",
    "\n",
    "audio_file = \"sample1.wav\"\n",
    "input_audio = download_and_load_audio_file(audio_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b442ecfd-85ab-4311-a4b7-33f2364d3b94",
   "metadata": {},
   "source": [
    "Now you can obtain the audio file with `download_and_load_audio_file` and perform a prediction through your predictor object. The wav files must be sampled at 16kHz. This is required by the automatic speech recognition models, so make sure to resample them if required. The input audio file must be less than 30 seconds. If you receive client error (413) please check the payload size to the endpoint. Payloads for SageMaker invoke endpoint requests are limited to about 5MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4900c8f5-b7a9-4984-a0ce-1ec7bd25f2d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" We are living in very exciting times with machine learning. The speed of ML model development will really actually increase. But you won't get to that end state that we want in the next coming years unless we actually make these models more accessible to everybody.\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = sm_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='audio/wav',\n",
    "    Body=input_audio\n",
    ")\n",
    "output=json.loads(response[\"Body\"].read().decode('utf-8'))['text'][0]\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fc6d60-f7d8-4251-924b-7d8f202b7d0b",
   "metadata": {},
   "source": [
    "The following example performs a translation task to convert a french audio file to english text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf40a010-9a20-4ced-bb9a-6e2e9204d370",
   "metadata": {},
   "source": [
    "## > Remove endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "193e21da-09e8-4b43-91ad-0c48bbaf516e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'f8a736e8-d608-4ec4-a816-25d0c22c402f',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'f8a736e8-d608-4ec4-a816-25d0c22c402f',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Thu, 13 Jun 2024 22:03:32 GMT',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c606017-49f8-4073-8dab-001ceaec54c3",
   "metadata": {},
   "source": [
    "## > Asynchronous Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bb7771bb-4bd9-4741-a5c6-61b61a9885c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## upload the sample file\n",
    "s3_key = f\"{prefix}/input/{audio_file}\"\n",
    "s3.upload_file(audio_file, bucket, s3_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d03506ad-84ef-44d5-bdaf-f1d53a264d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created duplicate copy s3://sagemaker-us-west-2-376678947624/whisper-sm-js/input/sample1_1.wav\n",
      "Created duplicate copy s3://sagemaker-us-west-2-376678947624/whisper-sm-js/input/sample1_2.wav\n",
      "Created duplicate copy s3://sagemaker-us-west-2-376678947624/whisper-sm-js/input/sample1_3.wav\n",
      "Created duplicate copy s3://sagemaker-us-west-2-376678947624/whisper-sm-js/input/sample1_4.wav\n",
      "Created duplicate copy s3://sagemaker-us-west-2-376678947624/whisper-sm-js/input/sample1_5.wav\n",
      "Created duplicate copy s3://sagemaker-us-west-2-376678947624/whisper-sm-js/input/sample1_6.wav\n",
      "Created duplicate copy s3://sagemaker-us-west-2-376678947624/whisper-sm-js/input/sample1_7.wav\n",
      "Created duplicate copy s3://sagemaker-us-west-2-376678947624/whisper-sm-js/input/sample1_8.wav\n",
      "Created duplicate copy s3://sagemaker-us-west-2-376678947624/whisper-sm-js/input/sample1_9.wav\n",
      "Created duplicate copy s3://sagemaker-us-west-2-376678947624/whisper-sm-js/input/sample1_10.wav\n"
     ]
    }
   ],
   "source": [
    "num_duplicates = 10\n",
    "\n",
    "# Create duplicate copies\n",
    "for i in range(num_duplicates):\n",
    "    duplicate_key = f\"{s3_key.rsplit('.', 1)[0]}_{i+1}.{s3_key.rsplit('.', 1)[1]}\"\n",
    "    copy_source = {\n",
    "        'Bucket': bucket,\n",
    "        'Key': s3_key\n",
    "    }\n",
    "    s3.copy_object(Bucket=bucket, Key=duplicate_key, CopySource=copy_source)\n",
    "    print(f\"Created duplicate copy s3://{bucket}/{duplicate_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ff26b57-6d78-450f-8e84-bf2eb601e206",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: whisper-sm-js-model-2024-06-13-21-50-59-718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.async_inference import AsyncInferenceConfig\n",
    "\n",
    "# Create an AsyncInferenceConfig object\n",
    "async_config = AsyncInferenceConfig(\n",
    "    output_path=f\"s3://{bucket}/{prefix}/output\", \n",
    "    max_concurrent_invocations_per_instance = 4,\n",
    "    # notification_config = {\n",
    "            #   \"SuccessTopic\": \"arn:aws:sns:us-east-2:123456789012:MyTopic\",\n",
    "            #   \"ErrorTopic\": \"arn:aws:sns:us-east-2:123456789012:MyTopic\",\n",
    "    # }, #  Notification configuration \n",
    ")\n",
    "\n",
    "# Deploy the model for async inference\n",
    "endpoint_name = name_from_base(f\"{prefix}-async-endpoint\")\n",
    "async_predictor = model.deploy(\n",
    "    async_inference_config=async_config,\n",
    "    initial_instance_count=1, # number of instances\n",
    "    instance_type='ml.g5.2xlarge', # instance type\n",
    "    endpoint_name=endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3053d30b-0c99-40bb-9924-bc25d6ddb79a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-376678947624/whisper-sm-js/output/44e5dc82-64b7-4a2b-bfdb-de390ebfea28.out\n",
      "s3://sagemaker-us-west-2-376678947624/whisper-sm-js/output/a2e53501-1517-45ae-ae23-04686c1da4bc.out\n",
      "s3://sagemaker-us-west-2-376678947624/whisper-sm-js/output/748af65c-bb2a-4fe9-bc0b-1252484041aa.out\n",
      "s3://sagemaker-us-west-2-376678947624/whisper-sm-js/output/53864457-57a3-4ee5-bb2b-46d6b9f61a04.out\n",
      "s3://sagemaker-us-west-2-376678947624/whisper-sm-js/output/e7fd84dc-f43f-4e05-9859-b5ca18545fe3.out\n",
      "s3://sagemaker-us-west-2-376678947624/whisper-sm-js/output/4e547c7a-d491-4121-ad0e-3eb1c1ead9e5.out\n",
      "s3://sagemaker-us-west-2-376678947624/whisper-sm-js/output/18bbcf7a-c9d3-4c52-9cc7-6069442d8266.out\n",
      "s3://sagemaker-us-west-2-376678947624/whisper-sm-js/output/47d76571-4469-4aa1-832c-04256e6ded02.out\n",
      "s3://sagemaker-us-west-2-376678947624/whisper-sm-js/output/e8028488-616b-4a96-b6d7-37d99292fde4.out\n",
      "s3://sagemaker-us-west-2-376678947624/whisper-sm-js/output/a6be3c2a-0729-4f73-b91a-839c3cd4b9dc.out\n",
      "s3://sagemaker-us-west-2-376678947624/whisper-sm-js/output/b1dc8a9c-68f8-4c66-9ed5-9e3d4c35d468.out\n"
     ]
    }
   ],
   "source": [
    "response = s3.list_objects_v2(Bucket=bucket, Prefix=f\"{prefix}/input/\")\n",
    "\n",
    "for obj in response.get('Contents', []):\n",
    "    key = obj['Key']\n",
    "    input_path = f\"s3://{bucket}/{key}\"\n",
    "\n",
    "    response = sm_runtime.invoke_endpoint_async(\n",
    "        EndpointName=endpoint_name,\n",
    "        InputLocation=input_path,\n",
    "        ContentType='audio/wav',\n",
    "        InvocationTimeoutSeconds=3600  # Set a 1 hour timeout\n",
    "    )\n",
    "\n",
    "    print(response[\"ResponseMetadata\"][\"HTTPHeaders\"][\"x-amzn-sagemaker-outputlocation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04d99e2",
   "metadata": {},
   "source": [
    "## > Remove endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c3b60c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '4b5713bb-f65f-4291-b77b-45908aa537c8',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '4b5713bb-f65f-4291-b77b-45908aa537c8',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Thu, 13 Jun 2024 21:49:42 GMT',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715d488e-87d0-4462-9fd6-49e68203830a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
